{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:24.322030Z",
     "iopub.status.busy": "2025-03-04T22:00:24.321735Z",
     "iopub.status.idle": "2025-03-04T22:00:24.334094Z",
     "shell.execute_reply": "2025-03-04T22:00:24.333440Z",
     "shell.execute_reply.started": "2025-03-04T22:00:24.322008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos cargados: 820834 filas, 68 columnas.\n"
     ]
    }
   ],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "path = os.path.join(\"X-IIoTID dataset.csv\")  \n",
    "try:\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    print(f\"✅ Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: No se encontró el archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:38.991536Z",
     "iopub.status.busy": "2025-03-04T22:00:38.991198Z",
     "iopub.status.idle": "2025-03-04T22:00:40.909252Z",
     "shell.execute_reply": "2025-03-04T22:00:40.908218Z",
     "shell.execute_reply.started": "2025-03-04T22:00:38.991501Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 820834 entries, 0 to 820833\n",
      "Data columns (total 68 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   Date                         820503 non-null  object\n",
      " 1   Timestamp                    820537 non-null  object\n",
      " 2   Scr_IP                       820834 non-null  object\n",
      " 3   Scr_port                     820834 non-null  object\n",
      " 4   Des_IP                       820834 non-null  object\n",
      " 5   Des_port                     820834 non-null  object\n",
      " 6   Protocol                     820834 non-null  object\n",
      " 7   Service                      820834 non-null  object\n",
      " 8   Duration                     820834 non-null  object\n",
      " 9   Scr_bytes                    820834 non-null  object\n",
      " 10  Des_bytes                    820834 non-null  object\n",
      " 11  Conn_state                   820834 non-null  int64 \n",
      " 12  missed_bytes                 820834 non-null  object\n",
      " 13  is_syn_only                  820834 non-null  bool  \n",
      " 14  Is_SYN_ACK                   820834 non-null  bool  \n",
      " 15  is_pure_ack                  820834 non-null  bool  \n",
      " 16  is_with_payload              820834 non-null  bool  \n",
      " 17  FIN or RST                   820834 non-null  bool  \n",
      " 18  Bad_checksum                 820834 non-null  bool  \n",
      " 19  is_SYN_with_RST              820834 non-null  bool  \n",
      " 20  Scr_pkts                     820834 non-null  object\n",
      " 21  Scr_ip_bytes                 820834 non-null  object\n",
      " 22  Des_pkts                     820834 non-null  object\n",
      " 23  Des_ip_bytes                 820834 non-null  object\n",
      " 24  anomaly_alert                820834 non-null  object\n",
      " 25  total_bytes                  820834 non-null  object\n",
      " 26  total_packet                 820834 non-null  object\n",
      " 27  paket_rate                   820834 non-null  object\n",
      " 28  byte_rate                    820834 non-null  object\n",
      " 29  Scr_packts_ratio             820834 non-null  object\n",
      " 30  Des_pkts_ratio               820834 non-null  object\n",
      " 31  Scr_bytes_ratio              820834 non-null  object\n",
      " 32  Des_bytes_ratio              820834 non-null  object\n",
      " 33  Avg_user_time                820834 non-null  object\n",
      " 34  Std_user_time                820834 non-null  object\n",
      " 35  Avg_nice_time                820834 non-null  object\n",
      " 36  Std_nice_time                820834 non-null  object\n",
      " 37  Avg_system_time              820834 non-null  object\n",
      " 38  Std_system_time              820834 non-null  object\n",
      " 39  Avg_iowait_time              820834 non-null  object\n",
      " 40  Std_iowait_time              820834 non-null  object\n",
      " 41  Avg_ideal_time               820834 non-null  object\n",
      " 42  Std_ideal_time               820834 non-null  object\n",
      " 43  Avg_tps                      820834 non-null  object\n",
      " 44  Std_tps                      820834 non-null  object\n",
      " 45  Avg_rtps                     820834 non-null  object\n",
      " 46  Std_rtps                     820834 non-null  object\n",
      " 47  Avg_wtps                     820834 non-null  object\n",
      " 48  Std_wtps                     820834 non-null  object\n",
      " 49  Avg_ldavg_1                  820834 non-null  object\n",
      " 50  Std_ldavg_1                  820834 non-null  object\n",
      " 51  Avg_kbmemused                820834 non-null  object\n",
      " 52  Std_kbmemused                820834 non-null  object\n",
      " 53  Avg_num_Proc/s               820834 non-null  object\n",
      " 54  Std_num_proc/s               820834 non-null  object\n",
      " 55  Avg_num_cswch/s              820834 non-null  object\n",
      " 56  std_num_cswch/s              820834 non-null  object\n",
      " 57  OSSEC_alert                  820834 non-null  int64 \n",
      " 58  OSSEC_alert_level            820834 non-null  int64 \n",
      " 59  Login_attempt                820834 non-null  int64 \n",
      " 60  Succesful_login              820834 non-null  int64 \n",
      " 61  File_activity                820834 non-null  int64 \n",
      " 62  Process_activity             820834 non-null  int64 \n",
      " 63  read_write_physical.process  820834 non-null  int64 \n",
      " 64  is_privileged                820834 non-null  int64 \n",
      " 65  class1                       820834 non-null  object\n",
      " 66  class2                       820834 non-null  object\n",
      " 67  class3                       820834 non-null  object\n",
      "dtypes: bool(7), int64(9), object(52)\n",
      "memory usage: 387.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:22:32.579423Z",
     "iopub.status.busy": "2025-03-04T22:22:32.579044Z",
     "iopub.status.idle": "2025-03-04T22:22:36.233846Z",
     "shell.execute_reply": "2025-03-04T22:22:36.233153Z",
     "shell.execute_reply.started": "2025-03-04T22:22:32.579395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"Divide los datos en entrenamiento, validación y prueba.\"\"\"\n",
    "X = df.drop(columns=['class1', 'class2', 'class3'])\n",
    "y_class3 = df['class3'].map({'Normal': 0, 'Attack': 1})\n",
    "y_class2 = df['class2']\n",
    "y_class1 = df['class1']\n",
    "\n",
    "X_train, X_temp, y_train_class3, y_temp_class3, y_train_class2, y_temp_class2, y_train_class1, y_temp_class1 = train_test_split(\n",
    "    X, y_class3, y_class2, y_class1, test_size=0.3, random_state=random_state, stratify=y_class3, shuffle=True\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val_class3, y_test_class3, y_val_class2, y_test_class2, y_val_class1, y_test_class1 = train_test_split(\n",
    "    X_temp, y_temp_class3, y_temp_class2, y_temp_class1, test_size=0.5, random_state=random_state, stratify=y_temp_class3, shuffle=True\n",
    ")\n",
    "\n",
    "# Resetear índices para evitar desalineaciones\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)  # Opcional\n",
    "\n",
    "y_train_class3 = y_train_class3.reset_index(drop=True)\n",
    "y_val_class3 = y_val_class3.reset_index(drop=True)\n",
    "y_test_class3 = y_test_class3.reset_index(drop=True)  # Opcional\n",
    "\n",
    "y_train_class2 = y_train_class2.reset_index(drop=True)\n",
    "y_val_class2 = y_val_class2.reset_index(drop=True)\n",
    "y_test_class2 = y_test_class2.reset_index(drop=True)  # Opcional\n",
    "\n",
    "y_train_class1 = y_train_class1.reset_index(drop=True)\n",
    "y_val_class1 = y_val_class1.reset_index(drop=True)\n",
    "y_test_class1 = y_test_class1.reset_index(drop=True)  # Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.871546Z",
     "iopub.status.busy": "2025-03-04T22:00:44.871294Z",
     "iopub.status.idle": "2025-03-04T22:00:44.878195Z",
     "shell.execute_reply": "2025-03-04T22:00:44.877408Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.871524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def fix_dtype(df, umbral_numerico=0.7):\n",
    "    object_cols = df.select_dtypes(include=['object']).columns\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns\n",
    "    bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "\n",
    "    # Convertir booleanos a float\n",
    "    df[bool_cols] = df[bool_cols].astype(float)\n",
    "\n",
    "    for col in object_cols:\n",
    "        valores_unicos = df[col].dropna().unique()\n",
    "\n",
    "        if {\"true\", \"false\"} <= set(valores_unicos):  # Verifica si ambos existen\n",
    "            df[col] = df[col].map({'true': 1, 'false': 0}).astype(float)\n",
    "        else:\n",
    "            converted = pd.to_numeric(df[col], errors='coerce')\n",
    "            if converted.notna().mean() > umbral_numerico:\n",
    "                df[col] = converted.astype(float)\n",
    "\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "def delete_ip_port(df):\n",
    "    \"\"\"Elimina las columnas 'ip' y 'port'.\"\"\"\n",
    "    lista = ['Scr_IP', 'Scr_port', 'Des_IP', 'Des_port', 'Scr_bytes', 'Des_bytes', 'Scr_pkts', \n",
    "                            'Des_pkts', 'Scr_ip_bytes', 'Des_ip_bytes', 'Scr_packts_ratio', 'Des_pkts_ratio',\n",
    "                            'Scr_bytes_ratio', 'Des_bytes_ratio']\n",
    "\n",
    "    return df.drop(columns=lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.879093Z",
     "iopub.status.busy": "2025-03-04T22:00:44.878818Z",
     "iopub.status.idle": "2025-03-04T22:00:44.900540Z",
     "shell.execute_reply": "2025-03-04T22:00:44.899675Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.879065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Reemplazos comunes de valores\n",
    "common_replacements = {\n",
    "    '-': np.nan,\n",
    "    '?': np.nan,\n",
    "    'nan': np.nan,\n",
    "}\n",
    "\n",
    "def replace_common_values(df):\n",
    "    \"\"\"Reemplaza valores comunes como '-', '?' y 'nan' por NaN.\"\"\"\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].replace(common_replacements)\n",
    "    return df\n",
    "\n",
    "def fix_mayus(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.901726Z",
     "iopub.status.busy": "2025-03-04T22:00:44.901415Z",
     "iopub.status.idle": "2025-03-04T22:00:44.917141Z",
     "shell.execute_reply": "2025-03-04T22:00:44.916356Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.901699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# Definir los imputadores\n",
    "imputers = {\n",
    "    'categorical': {\n",
    "        'most_frequent': SimpleImputer(strategy='most_frequent'),\n",
    "        'knn': KNNImputer(n_neighbors=5)\n",
    "    },\n",
    "    'numeric': {\n",
    "        'mean': SimpleImputer(strategy='mean'),\n",
    "        'median': SimpleImputer(strategy='median')\n",
    "    }\n",
    "}\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Definir escaladores\n",
    "scalers = {\n",
    "    \"robust\": RobustScaler(),\n",
    "    \"standard\": StandardScaler()\n",
    "}\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Definir codificadores\n",
    "encoders = {\n",
    "    \"one_hot\": OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "    \"ordinal\": OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.918287Z",
     "iopub.status.busy": "2025-03-04T22:00:44.918001Z",
     "iopub.status.idle": "2025-03-04T22:00:44.939138Z",
     "shell.execute_reply": "2025-03-04T22:00:44.938182Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.918258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imputador_cat= imputers['categorical']['most_frequent']\n",
    "imputador_num = imputers['numeric']['mean']\n",
    "normalizacion = scalers['robust']\n",
    "decodificador = encoders['one_hot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.942623Z",
     "iopub.status.busy": "2025-03-04T22:00:44.942393Z",
     "iopub.status.idle": "2025-03-04T22:00:44.958255Z",
     "shell.execute_reply": "2025-03-04T22:00:44.957465Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.942596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "\n",
    "def matriz_correlacion(df):\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    return correlation_matrix\n",
    "\n",
    "def correlacion_pares(df, umbral):\n",
    "    df = matriz_correlacion(df)\n",
    "    # Toma solo la parte superior de la matriz para evitar duplicados\n",
    "    upper_tri = df.where(np.triu(np.ones(df.shape), k=1).astype(bool))\n",
    "\n",
    "    # Identifica pares altamente correlacionados\n",
    "    correlated_pairs = []\n",
    "    for col in upper_tri.columns:\n",
    "        for row in upper_tri.index:\n",
    "            if upper_tri.loc[row, col] > umbral:\n",
    "                correlated_pairs.append((row, col))\n",
    "\n",
    "    # Selecciona las columnas a eliminar (de cada par, se elimina la que aparece como columna)\n",
    "    alta_corr_pares = [col for col in upper_tri.columns if any(upper_tri[col] > umbral)]\n",
    "    \n",
    "    return alta_corr_pares\n",
    "\n",
    "def correlacion_respecto_objetivo(df, target, umbral):\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Calculamos la correlación con la variable objetivo\n",
    "    target_correlation = df[numeric_cols].corrwith(target).abs().sort_values(ascending=True)\n",
    "\n",
    "    # Nos quedamos solo con las características que tengan correlación >= 0.1\n",
    "    baja_corr_respecto_obj = target_correlation[target_correlation < umbral].index.tolist()\n",
    "\n",
    "    return baja_corr_respecto_obj\n",
    "\n",
    "def seleccionar_variables_pca(X_train, X_val, n_components, num_top_features):\n",
    "    \"\"\"\n",
    "    Aplica PCA para seleccionar las características más influyentes, pero mantiene los datos originales.\n",
    "    \n",
    "    Parámetros:\n",
    "        - X_train: DataFrame de entrenamiento\n",
    "        - X_val: DataFrame de validación\n",
    "        - n_components: float/int, cantidad de componentes principales o porcentaje de varianza a retener\n",
    "        - num_top_features: int, número de características más influyentes a seleccionar\n",
    "\n",
    "    Retorna:\n",
    "        - X_train_filtrado: DataFrame de entrenamiento con las características seleccionadas\n",
    "        - X_val_filtrado: DataFrame de validación con las características seleccionadas\n",
    "    \"\"\"\n",
    "\n",
    "    # Si usas el sample, cambialo en las lineas necesarias\n",
    "    # X_train_sample = X_train.sample(n=300000, random_state=42) # Seleccionar una muestra de 300,000 instancias como en el articulo\n",
    "    \n",
    "    # Aplicar PCA (sin guardar la transformación)\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    pca.fit(X_train)  # Solo ajustamos el modelo, no transformamos los datos\n",
    "\n",
    "    # Obtener nombres originales de las variables\n",
    "    original_feature_names = np.array(X_train.columns)\n",
    "\n",
    "    # Contador de importancia de características en PCA\n",
    "    feature_counter = Counter()\n",
    "    \n",
    "    for comp in pca.components_:\n",
    "        top_indices = np.argsort(np.abs(comp))[-num_top_features:]  # Índices de las más importantes\n",
    "        top_features = original_feature_names[top_indices]  # Obtener nombres\n",
    "        feature_counter.update(top_features)  # Contar ocurrencias\n",
    "\n",
    "    # Seleccionar las variables más influyentes ordenadas por frecuencia de aparición\n",
    "    variables_pca = [feature for feature, _ in feature_counter.most_common()]\n",
    "\n",
    "    # Filtrar las variables seleccionadas en los conjuntos de datos\n",
    "    X_train_filtrado = X_train[variables_pca]\n",
    "    X_val_filtrado = X_val[variables_pca]\n",
    "    \n",
    "    return X_train_filtrado, X_val_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.960390Z",
     "iopub.status.busy": "2025-03-04T22:00:44.960153Z",
     "iopub.status.idle": "2025-03-04T22:00:44.982406Z",
     "shell.execute_reply": "2025-03-04T22:00:44.981553Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.960371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculo_varianza(df):\n",
    "    \"\"\"Calcula las varianzas de las columnas de un DataFrame y devuelve las que tienen varianza igual a cero.\"\"\"\n",
    "    varianzas = df.var()\n",
    "\n",
    "    # Identificar columnas con varianza igual a cero\n",
    "    variables_con_varianza_cero = [col for col, varianza in varianzas.items() if varianza == 0]\n",
    "    \n",
    "    return variables_con_varianza_cero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.983733Z",
     "iopub.status.busy": "2025-03-04T22:00:44.983404Z",
     "iopub.status.idle": "2025-03-04T22:01:16.561816Z",
     "shell.execute_reply": "2025-03-04T22:01:16.561075Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.983704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = replace_common_values(X_train)\n",
    "X_train = fix_mayus(X_train)\n",
    "X_train = fix_dtype(X_train)\n",
    "X_train = delete_ip_port(X_train)\n",
    "\n",
    "y_train_class3 = y_train_class3.loc[X_train.index]\n",
    "y_train_class2 = y_train_class2.loc[X_train.index]\n",
    "y_train_class1 = y_train_class1.loc[X_train.index]\n",
    "\n",
    "X_val = replace_common_values(X_val)\n",
    "X_val = fix_mayus(X_val)\n",
    "X_val = fix_dtype(X_val)\n",
    "X_val = delete_ip_port(X_val)\n",
    "\n",
    "y_val_class3 = y_val_class3.loc[X_val.index]\n",
    "y_val_class2 = y_val_class2.loc[X_val.index]\n",
    "y_val_class1 = y_val_class1.loc[X_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:20:27.080514Z",
     "iopub.status.busy": "2025-03-04T22:20:27.080077Z",
     "iopub.status.idle": "2025-03-04T22:20:31.272883Z",
     "shell.execute_reply": "2025-03-04T22:20:31.271899Z",
     "shell.execute_reply.started": "2025-03-04T22:20:27.080476Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Instancias completas: 416933, incompletas: 157650\n"
     ]
    }
   ],
   "source": [
    "X_train['Instancia_completa'] = X_train.notnull().all(axis=1).astype(int)\n",
    "X_val['Instancia_completa'] = X_val.notnull().all(axis=1).astype(int)\n",
    "\n",
    "completas = X_train['Instancia_completa'].sum()\n",
    "incompletas = len(X_train) - completas\n",
    "print(f\"✅ Instancias completas: {completas}, incompletas: {incompletas}\")\n",
    "sample_weight_train = X_train['Instancia_completa'].replace({1: 3, 0: 1})\n",
    "\n",
    "columnas_no_comprobar = [col for col in X_train.columns if col not in ['Timestamp', 'Date', 'Instancia_completa'] and X_train[col].dtypes != 'object']\n",
    "variables_con_varianza_cero = calculo_varianza(X_train[columnas_no_comprobar])\n",
    "X_train = X_train.drop(columns=variables_con_varianza_cero)\n",
    "X_val = X_val.drop(columns=variables_con_varianza_cero)\n",
    "    \n",
    "X_train = X_train.drop(columns=['Timestamp', 'Date', 'Instancia_completa'], errors='ignore')\n",
    "X_val = X_val.drop(columns=['Timestamp', 'Date', 'Instancia_completa'], errors='ignore')\n",
    "\n",
    "alta_corr_pares = correlacion_pares(X_train, 0.97)\n",
    "X_train = X_train.drop(columns=alta_corr_pares)\n",
    "X_val = X_val.drop(columns=alta_corr_pares)\n",
    "\n",
    "baja_corr_respecto_obj = correlacion_respecto_objetivo(X_train, y_train_class3, 0.025)\n",
    "X_train = X_train.drop(columns=baja_corr_respecto_obj)\n",
    "X_val = X_val.drop(columns=baja_corr_respecto_obj)\n",
    "\n",
    "caracteritisticas_seleccionadas = X_train.columns.tolist()\n",
    "\n",
    "X_train['Protocol'] = X_train['Protocol'].fillna(\"missing\")\n",
    "X_val['Protocol'] = X_val['Protocol'].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:21.406854Z",
     "iopub.status.busy": "2025-03-04T22:01:21.406638Z",
     "iopub.status.idle": "2025-03-04T22:01:24.205399Z",
     "shell.execute_reply": "2025-03-04T22:01:24.204668Z",
     "shell.execute_reply.started": "2025-03-04T22:01:21.406835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " # Identificar columnas categóricas, numéricas y booleanas\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "boolean_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "if boolean_cols.any():  # Si hay columnas booleanas\n",
    "    X_train[boolean_cols] = X_train[boolean_cols].astype(float)  # TAL VEZ INNCESESARIO\n",
    "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "##############################################################################\n",
    "    \n",
    "X_train[categorical_cols] = imputador_cat.fit_transform(X_train[categorical_cols])\n",
    "X_val[categorical_cols] = imputador_cat.transform(X_val[categorical_cols])\n",
    "\n",
    "X_train[numerical_cols] = imputador_num.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = imputador_num.transform(X_val[numerical_cols])\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_train_scaled = normalizacion.fit_transform(X_train[numerical_cols])\n",
    "X_val_scaled = normalizacion.transform(X_val[numerical_cols])\n",
    "\n",
    "# Convertir las matrices escaladas a DataFrames\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=[f\"{col}_scaled\" for col in numerical_cols], index=X_train.index)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=[f\"{col}_scaled\" for col in numerical_cols], index=X_val.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_train_encoded = decodificador.fit_transform(X_train[categorical_cols])\n",
    "X_val_encoded = decodificador.transform(X_val[categorical_cols])\n",
    "\n",
    "# Obtener los nombres de las nuevas columnas codificadas\n",
    "encoded_cols = decodificador.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Convertir las matrices codificadas a DataFrames\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_cols, index=X_train.index)\n",
    "X_val_encoded_df = pd.DataFrame(X_val_encoded, columns=encoded_cols, index=X_val.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Combinar con las características categóricas codificadas\n",
    "X_train_processed = pd.concat([X_train_scaled_df, X_train_encoded_df], axis=1)\n",
    "X_val_processed = pd.concat([X_val_scaled_df, X_val_encoded_df], axis=1)\n",
    "\n",
    "# Opcional: Reordenar las columnas si es necesario\n",
    "X_train = X_train_processed.reindex(sorted(X_train_processed.columns), axis=1)\n",
    "X_val = X_val_processed.reindex(sorted(X_val_processed.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:24.206527Z",
     "iopub.status.busy": "2025-03-04T22:01:24.206304Z",
     "iopub.status.idle": "2025-03-04T22:01:25.341273Z",
     "shell.execute_reply": "2025-03-04T22:01:25.340581Z",
     "shell.execute_reply.started": "2025-03-04T22:01:24.206506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val = seleccionar_variables_pca(X_train_processed, X_val_processed, n_components=0.95, num_top_features=20)\n",
    "caracteritisticas_procesadas = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:25.342409Z",
     "iopub.status.busy": "2025-03-04T22:01:25.342152Z",
     "iopub.status.idle": "2025-03-04T22:01:25.422582Z",
     "shell.execute_reply": "2025-03-04T22:01:25.421765Z",
     "shell.execute_reply.started": "2025-03-04T22:01:25.342387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574583, 34) (123125, 34)\n",
      "0 0\n",
      "class3\n",
      "0    0.5134\n",
      "1    0.4866\n",
      "Name: proportion, dtype: float64\n",
      "class3\n",
      "0    0.513405\n",
      "1    0.486595\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape)\n",
    "print(X_train.isnull().sum().sum(), X_val.isnull().sum().sum())\n",
    "print(y_train_class3.value_counts(normalize=True))\n",
    "print(y_val_class3.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_class3 = LabelEncoder()\n",
    "y_train_class3 = label_encoder_class3.fit_transform(y_train_class3)\n",
    "y_val_class3   = label_encoder_class3.transform(y_val_class3)\n",
    "y_test_class3  = label_encoder_class3.transform(y_test_class3)\n",
    "\n",
    "mapping_class3 = dict(enumerate(label_encoder_class3.classes_))\n",
    "\n",
    "\n",
    "label_encoder_class2 = LabelEncoder()\n",
    "y_train_class2 = label_encoder_class2.fit_transform(y_train_class2)\n",
    "y_val_class2   = label_encoder_class2.transform(y_val_class2)\n",
    "y_test_class2  = label_encoder_class2.transform(y_test_class2)\n",
    "\n",
    "mapping_class2 = dict(enumerate(label_encoder_class2.classes_))\n",
    "\n",
    "label_encoder_class1 = LabelEncoder()\n",
    "y_train_class1 = label_encoder_class1.fit_transform(y_train_class1)\n",
    "y_val_class1   = label_encoder_class1.transform(y_val_class1)\n",
    "y_test_class1  = label_encoder_class1.transform(y_test_class1)\n",
    "\n",
    "mapping_class1 = dict(enumerate(label_encoder_class1.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "{0: 'C&C', 1: 'Exfiltration', 2: 'Exploitation', 3: 'Lateral _movement', 4: 'Normal', 5: 'RDOS', 6: 'Reconnaissance', 7: 'Tampering', 8: 'Weaponization', 9: 'crypto-ransomware'}\n",
      "{0: 'BruteForce', 1: 'C&C', 2: 'Dictionary', 3: 'Discovering_resources', 4: 'Exfiltration', 5: 'Fake_notification', 6: 'False_data_injection', 7: 'Generic_scanning', 8: 'MQTT_cloud_broker_subscription', 9: 'MitM', 10: 'Modbus_register_reading', 11: 'Normal', 12: 'RDOS', 13: 'Reverse_shell', 14: 'Scanning_vulnerability', 15: 'TCP Relay', 16: 'crypto-ransomware', 17: 'fuzzing', 18: 'insider_malcious'}\n"
     ]
    }
   ],
   "source": [
    "print(mapping_class3)\n",
    "print(mapping_class2)\n",
    "print(mapping_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:25.423503Z",
     "iopub.status.busy": "2025-03-04T22:01:25.423293Z",
     "iopub.status.idle": "2025-03-04T22:01:25.501060Z",
     "shell.execute_reply": "2025-03-04T22:01:25.500214Z",
     "shell.execute_reply.started": "2025-03-04T22:01:25.423484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  # Número de características de entrada\n",
    "num_classes_2 = len(set(y_train_class2))  # Cantidad de clases en y_class2\n",
    "num_classes_1 = len(set(y_train_class1))  # Cantidad de clases en y_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:25.502460Z",
     "iopub.status.busy": "2025-03-04T22:01:25.502086Z",
     "iopub.status.idle": "2025-03-04T22:02:04.447982Z",
     "shell.execute_reply": "2025-03-04T22:02:04.447335Z",
     "shell.execute_reply.started": "2025-03-04T22:01:25.502429Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.1128 - val_accuracy: 0.9835 - val_loss: 0.0467\n",
      "Epoch 2/3\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0449 - val_accuracy: 0.9854 - val_loss: 0.0403\n",
      "Epoch 3/3\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0401 - val_accuracy: 0.9861 - val_loss: 0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_class1.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Entrada\n",
    "input_layer = keras.Input(shape=(input_dim,))\n",
    "\n",
    "# Capas ocultas\n",
    "x = layers.Dense(200, activation='relu')(input_layer)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "\n",
    "# Salidas\n",
    "output_class3 = layers.Dense(1, activation='sigmoid', name=\"output_class3\")(x)  # Binaria\n",
    "\n",
    "# Modelo con dos salidas\n",
    "model_class1 = keras.Model(inputs=input_layer, outputs=output_class3)\n",
    "\n",
    "# Compilar el modelo\n",
    "model_class1.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Definir el callback EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model_class1.fit(X_train,\n",
    "                    y_train_class3,\n",
    "                    batch_size=250,\n",
    "                    epochs=3,\n",
    "                    validation_data=(X_val, y_val_class3),\n",
    "                   callbacks=[early_stopping])\n",
    "\n",
    "# Guardar el modelo con un nombre único\n",
    "model_name = f\"modelo_class1\"\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "carpeta_modelos = \"modelos_cascada_dnn\"\n",
    "os.makedirs(carpeta_modelos, exist_ok=True)\n",
    "\n",
    "# Guardar el modelo dentro de la carpeta\n",
    "ruta_modelo = os.path.join(carpeta_modelos, f\"{model_name}.h5\")\n",
    "model_class1.save(ruta_modelo)\n",
    "\n",
    "print(f\"Modelo guardado en: {ruta_modelo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:04.449246Z",
     "iopub.status.busy": "2025-03-04T22:02:04.448959Z",
     "iopub.status.idle": "2025-03-04T22:02:09.969937Z",
     "shell.execute_reply": "2025-03-04T22:02:09.968948Z",
     "shell.execute_reply.started": "2025-03-04T22:02:04.449224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3848/3848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "(123125, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predicción para salida de clase3\n",
    "y_pred_class3 = model_class1.predict(X_val)\n",
    "y_pred_class3 = (y_pred_class3 >= 0.5).astype(int)\n",
    "print(y_pred_class3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:09.971353Z",
     "iopub.status.busy": "2025-03-04T22:02:09.971017Z",
     "iopub.status.idle": "2025-03-04T22:02:10.032147Z",
     "shell.execute_reply": "2025-03-04T22:02:10.031314Z",
     "shell.execute_reply.started": "2025-03-04T22:02:09.971320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "indices_train = np.where(y_train_class3 == 1)[0]\n",
    "X_train = X_train.iloc[indices_train]\n",
    "y_train_class2 = y_train_class2[indices_train]\n",
    "y_train_class2 = y_train_class2.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:10.033229Z",
     "iopub.status.busy": "2025-03-04T22:02:10.032980Z",
     "iopub.status.idle": "2025-03-04T22:02:10.050585Z",
     "shell.execute_reply": "2025-03-04T22:02:10.049686Z",
     "shell.execute_reply.started": "2025-03-04T22:02:10.033207Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59259, 34) (59259,)\n"
     ]
    }
   ],
   "source": [
    "indices_val = np.where(y_pred_class3 == 1)[0]\n",
    "X_val = X_val.iloc[indices_val]\n",
    "y_val_class2 = y_val_class2[indices_val].ravel()\n",
    "\n",
    "print(X_val.shape, y_val_class2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:10.197896Z",
     "iopub.status.busy": "2025-03-04T22:02:10.197595Z",
     "iopub.status.idle": "2025-03-04T22:02:30.946610Z",
     "shell.execute_reply": "2025-03-04T22:02:30.945713Z",
     "shell.execute_reply.started": "2025-03-04T22:02:10.197866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1685 - val_accuracy: 0.9882 - val_loss: 0.1784\n",
      "Epoch 2/10\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0223 - val_accuracy: 0.9892 - val_loss: 0.1636\n",
      "Epoch 3/10\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0122 - val_accuracy: 0.9895 - val_loss: 0.1792\n",
      "Epoch 4/10\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0101 - val_accuracy: 0.9896 - val_loss: 0.1691\n",
      "Epoch 5/10\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.9896 - val_loss: 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_class2.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Entrada\n",
    "input_layer = keras.Input(shape=(input_dim,))\n",
    "\n",
    "# Capas ocultas\n",
    "x = layers.Dense(200, activation='relu')(input_layer)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "\n",
    "# Salidas\n",
    "output_class2 = layers.Dense(num_classes_2, activation='softmax', name=\"output_class2\")(x)  # Multiclase Categoria\n",
    "\n",
    "# Modelo con dos salidas\n",
    "model_class2 = keras.Model(inputs=input_layer, outputs=output_class2)\n",
    "\n",
    "# Compilar el modelo\n",
    "model_class2.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Definir el callback EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model_class2.fit(X_train,\n",
    "                    y_train_class2,\n",
    "                    batch_size=250,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_val, y_val_class2),\n",
    "                   callbacks=[early_stopping])\n",
    "\n",
    "# Guardar el modelo con un nombre único\n",
    "model_name = f\"modelo_class2\"\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "carpeta_modelos = \"modelos_cascada_dnn\"\n",
    "os.makedirs(carpeta_modelos, exist_ok=True)\n",
    "\n",
    "# Guardar el modelo dentro de la carpeta\n",
    "ruta_modelo = os.path.join(carpeta_modelos, f\"{model_name}.h5\")\n",
    "model_class2.save(ruta_modelo)\n",
    "\n",
    "print(f\"Modelo guardado en: {ruta_modelo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:30.948025Z",
     "iopub.status.busy": "2025-03-04T22:02:30.947714Z",
     "iopub.status.idle": "2025-03-04T22:02:33.920231Z",
     "shell.execute_reply": "2025-03-04T22:02:33.919367Z",
     "shell.execute_reply.started": "2025-03-04T22:02:30.947995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1852/1852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "[3 6 8 ... 8 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Predicción para salida de clase2\n",
    "y_pred_class2 = model_class2.predict(X_val)\n",
    "y_pred_class2 = np.argmax(y_pred_class2, axis=1)\n",
    "print(y_pred_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:33.921425Z",
     "iopub.status.busy": "2025-03-04T22:02:33.921089Z",
     "iopub.status.idle": "2025-03-04T22:02:33.950982Z",
     "shell.execute_reply": "2025-03-04T22:02:33.950095Z",
     "shell.execute_reply.started": "2025-03-04T22:02:33.921401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train_class1 = y_train_class1[indices_train].ravel()\n",
    "y_val_class1 = y_val_class1[indices_val].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:34.061773Z",
     "iopub.status.busy": "2025-03-04T22:02:34.061491Z",
     "iopub.status.idle": "2025-03-04T22:02:51.356674Z",
     "shell.execute_reply": "2025-03-04T22:02:51.355961Z",
     "shell.execute_reply.started": "2025-03-04T22:02:34.061751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.5050 - loss: 1.8790 - val_accuracy: 0.8487 - val_loss: 1.0070\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8929 - loss: 0.5084 - val_accuracy: 0.8553 - val_loss: 1.2021\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9253 - loss: 0.2459 - val_accuracy: 0.8750 - val_loss: 1.4832\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9318 - loss: 0.1757 - val_accuracy: 0.9013 - val_loss: 1.5618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_Exploitation.h5\n",
      "**************************************************\n",
      "Epoch 1/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8794 - loss: 0.6004 - val_accuracy: 0.9731 - val_loss: 3.7099\n",
      "Epoch 2/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0404 - val_accuracy: 0.9775 - val_loss: 3.6574\n",
      "Epoch 3/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0463 - val_accuracy: 0.9712 - val_loss: 2.9051\n",
      "Epoch 4/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0173 - val_accuracy: 0.9769 - val_loss: 2.1279\n",
      "Epoch 5/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.9775 - val_loss: 2.9868\n",
      "Epoch 6/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0154 - val_accuracy: 0.9767 - val_loss: 1.8616\n",
      "Epoch 7/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.9775 - val_loss: 1.9360\n",
      "Epoch 8/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0077 - val_accuracy: 0.9769 - val_loss: 1.8237\n",
      "Epoch 9/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.9769 - val_loss: 1.9645\n",
      "Epoch 10/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0055 - val_accuracy: 0.9775 - val_loss: 1.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_Lateral _movement.h5\n",
      "**************************************************\n",
      "Epoch 1/10\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 0.3079 - val_accuracy: 0.9779 - val_loss: 0.4216\n",
      "Epoch 2/10\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9778 - val_loss: 0.4243\n",
      "Epoch 3/10\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9779 - val_loss: 0.4714\n",
      "Epoch 4/10\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 9.9467e-04 - val_accuracy: 0.9779 - val_loss: 0.4431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_Reconnaissance.h5\n",
      "**************************************************\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7835 - loss: 1.7991 - val_accuracy: 0.9890 - val_loss: 0.2241\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0416 - val_accuracy: 0.9890 - val_loss: 0.2386\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.9890 - val_loss: 0.2644\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.0058 - val_accuracy: 0.9918 - val_loss: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_Tampering.h5\n",
      "**************************************************\n",
      "Epoch 1/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.2137 - val_accuracy: 0.9985 - val_loss: 0.0308\n",
      "Epoch 2/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5852e-05 - val_accuracy: 0.9985 - val_loss: 0.0338\n",
      "Epoch 3/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4859e-05 - val_accuracy: 0.9985 - val_loss: 0.0352\n",
      "Epoch 4/10\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5862e-05 - val_accuracy: 0.9985 - val_loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_cascada_dnn\\modelo_Weaponization.h5\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "modelos = []  # Lista para almacenar los modelos\n",
    "\n",
    "class_names = np.unique(y_train_class2)\n",
    "for name in class_names:\n",
    "\n",
    "    indices_train_cat = np.where(y_train_class2 == name)[0]\n",
    "    X_train_cat = X_train.iloc[indices_train_cat]\n",
    "    y_train_class1_cat = y_train_class1[indices_train_cat]\n",
    "    \n",
    "    if np.unique(y_train_class1_cat).size == 1:\n",
    "        continue  \n",
    "\n",
    "    indices_val_cat = np.where(y_pred_class2 == name)[0]\n",
    "    X_val_cat = X_val.iloc[indices_val_cat]\n",
    "    y_val_class1_cat = y_val_class1[indices_val_cat]\n",
    "\n",
    "    # Entrada\n",
    "    input_layer = keras.Input(shape=(input_dim,))\n",
    "    \n",
    "    # Capas ocultas\n",
    "    x = layers.Dense(200, activation='relu')(input_layer)\n",
    "    x = layers.Dense(200, activation='relu')(x)\n",
    "    x = layers.Dense(200, activation='relu')(x)\n",
    "    \n",
    "    # Salidas\n",
    "    output_class1 = layers.Dense(num_classes_1, activation='softmax', name=\"output_class1\")(x)  # Multiclase Categoria\n",
    "    \n",
    "    # Modelo con dos salidas\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_class1)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Definir el callback EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train_cat,\n",
    "                        y_train_class1_cat,\n",
    "                        batch_size=250,\n",
    "                        epochs=10,\n",
    "                        validation_data=(X_val_cat, y_val_class1_cat),\n",
    "                        callbacks=[early_stopping])\n",
    "    \n",
    "    # Guardar el modelo con un nombre único\n",
    "    nombre = mapping_class2[name]\n",
    "    model_name = f\"modelo_{nombre}\"\n",
    "    \n",
    "    # Crear la carpeta si no existe\n",
    "    carpeta_modelos = \"modelos_cascada_dnn\"\n",
    "    os.makedirs(carpeta_modelos, exist_ok=True)\n",
    "\n",
    "    # Guardar el modelo dentro de la carpeta\n",
    "    ruta_modelo = os.path.join(carpeta_modelos, f\"{model_name}.h5\")\n",
    "    model.save(ruta_modelo)\n",
    "\n",
    "    print(f\"Modelo guardado en: {ruta_modelo}\")\n",
    "\n",
    "    \n",
    "    # Añadir el modelo a la lista\n",
    "    modelos.append((model_name, model))  # Almacena el nombre y el modelo\n",
    "    \n",
    "    print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:51.357812Z",
     "iopub.status.busy": "2025-03-04T22:02:51.357573Z",
     "iopub.status.idle": "2025-03-04T22:03:05.424662Z",
     "shell.execute_reply": "2025-03-04T22:03:05.423735Z",
     "shell.execute_reply.started": "2025-03-04T22:02:51.357791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1852/1852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1852/1852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1852/1852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m1852/1852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1852/1852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Predicciones para modelo_Exploitation:\n",
      "[13 13 13 ... 13 13 13]\n",
      "Predicciones para modelo_Lateral _movement:\n",
      "[10 15 15 ... 15  8  8]\n",
      "Predicciones para modelo_Reconnaissance:\n",
      "[17 14 14 ... 14  3  3]\n",
      "Predicciones para modelo_Tampering:\n",
      "[6 6 6 ... 6 6 6]\n",
      "Predicciones para modelo_Weaponization:\n",
      "[2 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predicciones = {}  # Diccionario para almacenar las predicciones de cada modelo\n",
    "\n",
    "for model_name, model in modelos:\n",
    "    y_pred_class2 = model.predict(X_val)\n",
    "    y_pred_class2 = np.argmax(y_pred_class2, axis=1)\n",
    "    \n",
    "    # Guardar las predicciones en un diccionario con el nombre del modelo\n",
    "    predicciones[model_name] = y_pred_class2\n",
    "\n",
    "# Mostrar las predicciones de cada modelo\n",
    "for name, pred in predicciones.items():\n",
    "    print(f\"Predicciones para {name}:\")\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:23:04.513589Z",
     "iopub.status.busy": "2025-03-04T22:23:04.513289Z",
     "iopub.status.idle": "2025-03-04T22:23:09.940421Z",
     "shell.execute_reply": "2025-03-04T22:23:09.939141Z",
     "shell.execute_reply.started": "2025-03-04T22:23:04.513567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = replace_common_values(X_test)\n",
    "X_test = fix_mayus(X_test)\n",
    "X_test = fix_dtype(X_test)\n",
    "X_test = delete_ip_port(X_test)\n",
    "\n",
    "y_test_class3 = y_test_class3[X_test.index]\n",
    "\n",
    "X_test = X_test[caracteritisticas_seleccionadas] \n",
    "\n",
    "X_test['Protocol'] = X_test['Protocol'].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:22:19.991724Z",
     "iopub.status.busy": "2025-03-04T22:22:19.991425Z",
     "iopub.status.idle": "2025-03-04T22:22:20.078513Z",
     "shell.execute_reply": "2025-03-04T22:22:20.077337Z",
     "shell.execute_reply.started": "2025-03-04T22:22:19.991701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Identificar columnas categóricas, numéricas y booleanas\n",
    "categorical_cols = X_test.select_dtypes(include=['object']).columns\n",
    "boolean_cols = X_test.select_dtypes(include=['bool']).columns\n",
    "if boolean_cols.any():  # Si hay columnas booleanas\n",
    "    X_test[boolean_cols] = X_test[boolean_cols].astype(float) # TAL VEZ INNCESESARIO\n",
    "numerical_cols = X_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_test[categorical_cols] = imputador_cat.transform(X_test[categorical_cols])\n",
    "\n",
    "X_test[numerical_cols] = imputador_num.transform(X_test[numerical_cols])\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_test_scaled = normalizacion.transform(X_test[numerical_cols])\n",
    "\n",
    "# Convertir las matrices escaladas a DataFrames\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=[f\"{col}_scaled\" for col in numerical_cols], index=X_test.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_test_encoded = decodificador.transform(X_test[categorical_cols])\n",
    "\n",
    "# Obtener los nombres de las nuevas columnas codificadas\n",
    "encoded_cols = decodificador.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Convertir las matrices codificadas a DataFrames\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Combinar con las características categóricas codificadas\n",
    "X_test_processed = pd.concat([X_test_scaled_df, X_test_encoded_df], axis=1)\n",
    "\n",
    "# Opcional: Reordenar las columnas si es necesario\n",
    "X_test_processed = X_test_processed.reindex(sorted(X_test_processed.columns), axis=1)\n",
    "\n",
    "X_test = X_test_processed[caracteritisticas_procesadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:08:07.652427Z",
     "iopub.status.busy": "2025-03-04T22:08:07.652090Z",
     "iopub.status.idle": "2025-03-04T22:08:12.933506Z",
     "shell.execute_reply": "2025-03-04T22:08:12.932697Z",
     "shell.execute_reply.started": "2025-03-04T22:08:07.652402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3848/3848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Predicción para salida de clase3\n",
    "y_pred_class3 = model_class1.predict(X_test)\n",
    "y_pred_class3 = (y_pred_class3 >= 0.5).astype(int)\n",
    "print(y_pred_class3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:08:12.934858Z",
     "iopub.status.busy": "2025-03-04T22:08:12.934564Z",
     "iopub.status.idle": "2025-03-04T22:08:12.943039Z",
     "shell.execute_reply": "2025-03-04T22:08:12.942400Z",
     "shell.execute_reply.started": "2025-03-04T22:08:12.934835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_class3, y_pred_class3)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:08:12.944642Z",
     "iopub.status.busy": "2025-03-04T22:08:12.944336Z",
     "iopub.status.idle": "2025-03-04T22:08:12.976905Z",
     "shell.execute_reply": "2025-03-04T22:08:12.976180Z",
     "shell.execute_reply.started": "2025-03-04T22:08:12.944605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "indices_test = np.where(y_pred_class3 == 1)[0]\n",
    "X_test = X_test.iloc[indices_test]\n",
    "y_test_class2 = y_test_class2[indices_test].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:08:26.930934Z",
     "iopub.status.busy": "2025-03-04T22:08:26.930651Z",
     "iopub.status.idle": "2025-03-04T22:08:29.612913Z",
     "shell.execute_reply": "2025-03-04T22:08:29.611934Z",
     "shell.execute_reply.started": "2025-03-04T22:08:26.930913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1853/1853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicción para salida de clase2\n",
    "y_pred_class2 = model_class2.predict(X_test)\n",
    "y_pred_class2 = np.argmax(y_pred_class2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:08:29.875022Z",
     "iopub.status.busy": "2025-03-04T22:08:29.874757Z",
     "iopub.status.idle": "2025-03-04T22:08:29.881673Z",
     "shell.execute_reply": "2025-03-04T22:08:29.880911Z",
     "shell.execute_reply.started": "2025-03-04T22:08:29.874997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_class2, y_pred_class2)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clase2 Mapping: {0: 'C&C', 1: 'Exfiltration', 2: 'Exploitation', 3: 'Lateral _movement', 4: 'RDOS', 5: 'Reconnaissance', 6: 'Tampering', 7: 'Weaponization', 8: 'crypto-ransomware'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clase1 Mapping: {0: 'BruteForce', 1: 'C&C', 2: 'Dictionary', 3: 'Discovering_resources', 4: 'Exfiltration', 5: 'Fake_notification', 6: 'False_data_injection', 7: 'Generic_scanning', 8: 'MQTT_cloud_broker_subscription', 9: 'MitM', 10: 'Modbus_register_reading', 11: 'RDOS', 12: 'Reverse_shell', 13: 'Scanning_vulnerability', 14: 'TCP Relay', 15: 'crypto-ransomware', 16: 'fuzzing', 17: 'insider_malcious'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class1 = y_test_class1[indices_test].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeo de nombres a números: {'C&C': 0, 'Exfiltration': 1, 'Exploitation': 2, 'Lateral _movement': 3, 'Normal': 4, 'RDOS': 5, 'Reconnaissance': 6, 'Tampering': 7, 'Weaponization': 8, 'crypto-ransomware': 9}\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario con {nombre: número de clase}\n",
    "class_name_to_number = {value: key for key, value in mapping_class2.items()}\n",
    "\n",
    "print(\"Mapeo de nombres a números:\", class_name_to_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:13:53.626487Z",
     "iopub.status.busy": "2025-03-04T22:13:53.626091Z",
     "iopub.status.idle": "2025-03-04T22:13:55.844187Z",
     "shell.execute_reply": "2025-03-04T22:13:55.843325Z",
     "shell.execute_reply.started": "2025-03-04T22:13:53.626457Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase Exploitation, Valores únicos en y_test_class1_cat: (array([ 9, 11, 13, 15]), array([  8,  14, 112,   3], dtype=int64))\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para Exploitation: 0.8175\n",
      "**************************************************\n",
      "\n",
      "Clase Lateral _movement, Valores únicos en y_test_class1_cat: (array([ 2,  3,  6,  7,  8, 10, 11, 13, 14, 15, 16, 18]), array([   1,    1,   16,   12, 3520,  930,   40,   19,    5,  210,    1,\n",
      "          1], dtype=int64))\n",
      "WARNING:tensorflow:5 out of the last 324 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E251A2C220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 324 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E251A2C220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy para Lateral _movement: 0.9796\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase Reconnaissance, Valores únicos en y_test_class1_cat: (array([ 1,  3,  4,  7,  8, 11, 12, 13, 14, 15, 17]), array([   1, 2631,    2, 7536,   18,  419,    8,   12, 7900,    6,   97],\n",
      "      dtype=int64))\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Accuracy para Reconnaissance: 0.9748\n",
      "**************************************************\n",
      "\n",
      "Clase Tampering, Valores únicos en y_test_class1_cat: (array([ 5,  6,  8, 11, 15]), array([  2, 727,   2,   2,   2], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para Tampering: 0.9891\n",
      "**************************************************\n",
      "\n",
      "Clase Weaponization, Valores únicos en y_test_class1_cat: (array([ 0,  2,  4, 11, 14, 18]), array([7152,  375,    1,    2,    4, 2637], dtype=int64))\n",
      "\u001b[1m318/318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy para Weaponization: 0.9993\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class_names = ['Exploitation', 'Lateral _movement', 'Reconnaissance', 'Tampering', 'Weaponization']\n",
    "\n",
    "for name in class_names:\n",
    "    # Obtener el número de clase correspondiente al nombre\n",
    "    if name not in class_name_to_number:\n",
    "        print(f\"Clase {name} no encontrada en el mapeo, saltando...\")\n",
    "        continue  \n",
    "\n",
    "    class_number = class_name_to_number[name]\n",
    "\n",
    "    # Filtrar índices de la clase\n",
    "    indices_test_cat = np.where(y_pred_class2 == class_number)[0]\n",
    "\n",
    "    # Verificar si hay datos antes de continuar\n",
    "    if len(indices_test_cat) == 0:\n",
    "        print(f\"No hay datos para la clase {name}, saltando...\")\n",
    "        continue  \n",
    "\n",
    "    X_test_processed_cat = X_test.iloc[indices_test_cat]\n",
    "    y_test_class1_cat = y_test_class1[indices_test_cat]\n",
    "\n",
    "    print(f\"Clase {name}, Valores únicos en y_test_class1_cat:\", np.unique(y_test_class1_cat, return_counts=True))\n",
    "\n",
    "    # Cargar el modelo correspondiente\n",
    "    model = load_model(os.path.join(\"modelos_cascada_dnn\", f\"modelo_{name}.h5\"))\n",
    "\n",
    "    # Hacer la predicción\n",
    "    y_pred_class1 = model.predict(X_test_processed_cat)\n",
    "    y_pred_class1 = np.argmax(y_pred_class1, axis=1)  \n",
    "\n",
    "    accuracy = accuracy_score(y_test_class1_cat, y_pred_class1)\n",
    "    print(f\"Accuracy para {name}: {accuracy:.4f}\")\n",
    "\n",
    "    print(\"*\" * 50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6649121,
     "sourceId": 10725550,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
