{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:24.322030Z",
     "iopub.status.busy": "2025-03-04T22:00:24.321735Z",
     "iopub.status.idle": "2025-03-04T22:00:24.334094Z",
     "shell.execute_reply": "2025-03-04T22:00:24.333440Z",
     "shell.execute_reply.started": "2025-03-04T22:00:24.322008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos cargados: 820834 filas, 68 columnas.\n"
     ]
    }
   ],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "path = os.path.join(\"X-IIoTID dataset.csv\")  \n",
    "try:\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    print(f\"✅ Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: No se encontró el archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:38.991536Z",
     "iopub.status.busy": "2025-03-04T22:00:38.991198Z",
     "iopub.status.idle": "2025-03-04T22:00:40.909252Z",
     "shell.execute_reply": "2025-03-04T22:00:40.908218Z",
     "shell.execute_reply.started": "2025-03-04T22:00:38.991501Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 820834 entries, 0 to 820833\n",
      "Data columns (total 68 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   Date                         820503 non-null  object\n",
      " 1   Timestamp                    820537 non-null  object\n",
      " 2   Scr_IP                       820834 non-null  object\n",
      " 3   Scr_port                     820834 non-null  object\n",
      " 4   Des_IP                       820834 non-null  object\n",
      " 5   Des_port                     820834 non-null  object\n",
      " 6   Protocol                     820834 non-null  object\n",
      " 7   Service                      820834 non-null  object\n",
      " 8   Duration                     820834 non-null  object\n",
      " 9   Scr_bytes                    820834 non-null  object\n",
      " 10  Des_bytes                    820834 non-null  object\n",
      " 11  Conn_state                   820834 non-null  int64 \n",
      " 12  missed_bytes                 820834 non-null  object\n",
      " 13  is_syn_only                  820834 non-null  bool  \n",
      " 14  Is_SYN_ACK                   820834 non-null  bool  \n",
      " 15  is_pure_ack                  820834 non-null  bool  \n",
      " 16  is_with_payload              820834 non-null  bool  \n",
      " 17  FIN or RST                   820834 non-null  bool  \n",
      " 18  Bad_checksum                 820834 non-null  bool  \n",
      " 19  is_SYN_with_RST              820834 non-null  bool  \n",
      " 20  Scr_pkts                     820834 non-null  object\n",
      " 21  Scr_ip_bytes                 820834 non-null  object\n",
      " 22  Des_pkts                     820834 non-null  object\n",
      " 23  Des_ip_bytes                 820834 non-null  object\n",
      " 24  anomaly_alert                820834 non-null  object\n",
      " 25  total_bytes                  820834 non-null  object\n",
      " 26  total_packet                 820834 non-null  object\n",
      " 27  paket_rate                   820834 non-null  object\n",
      " 28  byte_rate                    820834 non-null  object\n",
      " 29  Scr_packts_ratio             820834 non-null  object\n",
      " 30  Des_pkts_ratio               820834 non-null  object\n",
      " 31  Scr_bytes_ratio              820834 non-null  object\n",
      " 32  Des_bytes_ratio              820834 non-null  object\n",
      " 33  Avg_user_time                820834 non-null  object\n",
      " 34  Std_user_time                820834 non-null  object\n",
      " 35  Avg_nice_time                820834 non-null  object\n",
      " 36  Std_nice_time                820834 non-null  object\n",
      " 37  Avg_system_time              820834 non-null  object\n",
      " 38  Std_system_time              820834 non-null  object\n",
      " 39  Avg_iowait_time              820834 non-null  object\n",
      " 40  Std_iowait_time              820834 non-null  object\n",
      " 41  Avg_ideal_time               820834 non-null  object\n",
      " 42  Std_ideal_time               820834 non-null  object\n",
      " 43  Avg_tps                      820834 non-null  object\n",
      " 44  Std_tps                      820834 non-null  object\n",
      " 45  Avg_rtps                     820834 non-null  object\n",
      " 46  Std_rtps                     820834 non-null  object\n",
      " 47  Avg_wtps                     820834 non-null  object\n",
      " 48  Std_wtps                     820834 non-null  object\n",
      " 49  Avg_ldavg_1                  820834 non-null  object\n",
      " 50  Std_ldavg_1                  820834 non-null  object\n",
      " 51  Avg_kbmemused                820834 non-null  object\n",
      " 52  Std_kbmemused                820834 non-null  object\n",
      " 53  Avg_num_Proc/s               820834 non-null  object\n",
      " 54  Std_num_proc/s               820834 non-null  object\n",
      " 55  Avg_num_cswch/s              820834 non-null  object\n",
      " 56  std_num_cswch/s              820834 non-null  object\n",
      " 57  OSSEC_alert                  820834 non-null  int64 \n",
      " 58  OSSEC_alert_level            820834 non-null  int64 \n",
      " 59  Login_attempt                820834 non-null  int64 \n",
      " 60  Succesful_login              820834 non-null  int64 \n",
      " 61  File_activity                820834 non-null  int64 \n",
      " 62  Process_activity             820834 non-null  int64 \n",
      " 63  read_write_physical.process  820834 non-null  int64 \n",
      " 64  is_privileged                820834 non-null  int64 \n",
      " 65  class1                       820834 non-null  object\n",
      " 66  class2                       820834 non-null  object\n",
      " 67  class3                       820834 non-null  object\n",
      "dtypes: bool(7), int64(9), object(52)\n",
      "memory usage: 387.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:22:32.579423Z",
     "iopub.status.busy": "2025-03-04T22:22:32.579044Z",
     "iopub.status.idle": "2025-03-04T22:22:36.233846Z",
     "shell.execute_reply": "2025-03-04T22:22:36.233153Z",
     "shell.execute_reply.started": "2025-03-04T22:22:32.579395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"Divide los datos en entrenamiento, validación y prueba.\"\"\"\n",
    "X = df.drop(columns=['class1', 'class2', 'class3'])\n",
    "y_class3 = df['class3'].map({'Normal': 0, 'Attack': 1})\n",
    "y_class2 = df['class2']\n",
    "y_class1 = df['class1']\n",
    "\n",
    "X_train, X_temp, y_train_class3, y_temp_class3, y_train_class2, y_temp_class2, y_train_class1, y_temp_class1 = train_test_split(\n",
    "    X, y_class3, y_class2, y_class1, test_size=0.3, random_state=random_state, stratify=y_class3, shuffle=True\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val_class3, y_test_class3, y_val_class2, y_test_class2, y_val_class1, y_test_class1 = train_test_split(\n",
    "    X_temp, y_temp_class3, y_temp_class2, y_temp_class1, test_size=0.5, random_state=random_state, stratify=y_temp_class3, shuffle=True\n",
    ")\n",
    "\n",
    "# Resetear índices para evitar desalineaciones\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)  # Opcional\n",
    "\n",
    "y_train_class3 = y_train_class3.reset_index(drop=True)\n",
    "y_val_class3 = y_val_class3.reset_index(drop=True)\n",
    "y_test_class3 = y_test_class3.reset_index(drop=True)  # Opcional\n",
    "\n",
    "y_train_class2 = y_train_class2.reset_index(drop=True)\n",
    "y_val_class2 = y_val_class2.reset_index(drop=True)\n",
    "y_test_class2 = y_test_class2.reset_index(drop=True)  # Opcional\n",
    "\n",
    "y_train_class1 = y_train_class1.reset_index(drop=True)\n",
    "y_val_class1 = y_val_class1.reset_index(drop=True)\n",
    "y_test_class1 = y_test_class1.reset_index(drop=True)  # Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.871546Z",
     "iopub.status.busy": "2025-03-04T22:00:44.871294Z",
     "iopub.status.idle": "2025-03-04T22:00:44.878195Z",
     "shell.execute_reply": "2025-03-04T22:00:44.877408Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.871524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def fix_dtype(df, umbral_numerico=0.7):\n",
    "    object_cols = df.select_dtypes(include=['object']).columns\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns\n",
    "    bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "\n",
    "    # Convertir booleanos a float\n",
    "    df[bool_cols] = df[bool_cols].astype(float)\n",
    "\n",
    "    for col in object_cols:\n",
    "        valores_unicos = df[col].dropna().unique()\n",
    "\n",
    "        if {\"true\", \"false\"} <= set(valores_unicos):  # Verifica si ambos existen\n",
    "            df[col] = df[col].map({'true': 1, 'false': 0}).astype(float)\n",
    "        else:\n",
    "            converted = pd.to_numeric(df[col], errors='coerce')\n",
    "            if converted.notna().mean() > umbral_numerico:\n",
    "                df[col] = converted.astype(float)\n",
    "\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "def delete_ip_port(df):\n",
    "    \"\"\"Elimina las columnas 'ip' y 'port'.\"\"\"\n",
    "    lista = ['Scr_IP', 'Scr_port', 'Des_IP', 'Des_port', 'Scr_bytes', 'Des_bytes', 'Scr_pkts', \n",
    "                            'Des_pkts', 'Scr_ip_bytes', 'Des_ip_bytes', 'Scr_packts_ratio', 'Des_pkts_ratio',\n",
    "                            'Scr_bytes_ratio', 'Des_bytes_ratio']\n",
    "\n",
    "    return df.drop(columns=lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.879093Z",
     "iopub.status.busy": "2025-03-04T22:00:44.878818Z",
     "iopub.status.idle": "2025-03-04T22:00:44.900540Z",
     "shell.execute_reply": "2025-03-04T22:00:44.899675Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.879065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Reemplazos comunes de valores\n",
    "common_replacements = {\n",
    "    '-': np.nan,\n",
    "    '?': np.nan,\n",
    "    'nan': np.nan,\n",
    "}\n",
    "\n",
    "def replace_common_values(df):\n",
    "    \"\"\"Reemplaza valores comunes como '-', '?' y 'nan' por NaN.\"\"\"\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].replace(common_replacements)\n",
    "    return df\n",
    "\n",
    "def fix_mayus(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.901726Z",
     "iopub.status.busy": "2025-03-04T22:00:44.901415Z",
     "iopub.status.idle": "2025-03-04T22:00:44.917141Z",
     "shell.execute_reply": "2025-03-04T22:00:44.916356Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.901699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# Definir los imputadores\n",
    "imputers = {\n",
    "    'categorical': {\n",
    "        'most_frequent': SimpleImputer(strategy='most_frequent'),\n",
    "        'knn': KNNImputer(n_neighbors=5),\n",
    "        'constant': SimpleImputer(strategy='constant', fill_value='missing')\n",
    "    },\n",
    "    'numeric': {\n",
    "        'mean': SimpleImputer(strategy='mean'),\n",
    "        'median': SimpleImputer(strategy='median')\n",
    "    }\n",
    "}\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Definir escaladores\n",
    "scalers = {\n",
    "    \"robust\": RobustScaler(),\n",
    "    \"standard\": StandardScaler()\n",
    "}\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Definir codificadores\n",
    "encoders = {\n",
    "    \"one_hot\": OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "    \"ordinal\": OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.918287Z",
     "iopub.status.busy": "2025-03-04T22:00:44.918001Z",
     "iopub.status.idle": "2025-03-04T22:00:44.939138Z",
     "shell.execute_reply": "2025-03-04T22:00:44.938182Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.918258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imputador_cat= imputers['categorical']['constant']\n",
    "imputador_num = imputers['numeric']['mean']\n",
    "normalizacion = scalers['robust']\n",
    "decodificador = encoders['one_hot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.942623Z",
     "iopub.status.busy": "2025-03-04T22:00:44.942393Z",
     "iopub.status.idle": "2025-03-04T22:00:44.958255Z",
     "shell.execute_reply": "2025-03-04T22:00:44.957465Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.942596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def matriz_correlacion(df):\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    return correlation_matrix\n",
    "\n",
    "def correlacion_pares(df, umbral):\n",
    "    df = matriz_correlacion(df)\n",
    "    # Toma solo la parte superior de la matriz para evitar duplicados\n",
    "    upper_tri = df.where(np.triu(np.ones(df.shape), k=1).astype(bool))\n",
    "\n",
    "    # Identifica pares altamente correlacionados\n",
    "    correlated_pairs = []\n",
    "    for col in upper_tri.columns:\n",
    "        for row in upper_tri.index:\n",
    "            if upper_tri.loc[row, col] > umbral:\n",
    "                correlated_pairs.append((row, col))\n",
    "\n",
    "    # Selecciona las columnas a eliminar (de cada par, se elimina la que aparece como columna)\n",
    "    alta_corr_pares = [col for col in upper_tri.columns if any(upper_tri[col] > umbral)]\n",
    "    \n",
    "    return alta_corr_pares\n",
    "\n",
    "def correlacion_respecto_objetivo(df, target, umbral):\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Calculamos la correlación con la variable objetivo\n",
    "    target_correlation = df[numeric_cols].corrwith(target).abs().sort_values(ascending=True)\n",
    "\n",
    "    # Nos quedamos solo con las características que tengan correlación >= 0.1\n",
    "    baja_corr_respecto_obj = target_correlation[target_correlation < umbral].index.tolist()\n",
    "\n",
    "    return baja_corr_respecto_obj\n",
    "\n",
    "def seleccionar_variables_pca(X_train, X_val, n_components, num_top_features):\n",
    "    \"\"\"\n",
    "    Aplica PCA para seleccionar las características más influyentes, pero mantiene los datos originales.\n",
    "    \n",
    "    Parámetros:\n",
    "        - X_train: DataFrame de entrenamiento\n",
    "        - X_val: DataFrame de validación\n",
    "        - n_components: float/int, cantidad de componentes principales o porcentaje de varianza a retener\n",
    "        - num_top_features: int, número de características más influyentes a seleccionar\n",
    "\n",
    "    Retorna:\n",
    "        - X_train_filtrado: DataFrame de entrenamiento con las características seleccionadas\n",
    "        - X_val_filtrado: DataFrame de validación con las características seleccionadas\n",
    "    \"\"\"\n",
    "\n",
    "    # Si usas el sample, cambialo en las lineas necesarias\n",
    "    # X_train_sample = X_train.sample(n=300000, random_state=42) # Seleccionar una muestra de 300,000 instancias como en el articulo\n",
    "    \n",
    "    # Aplicar PCA (sin guardar la transformación)\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    pca.fit(X_train)  # Solo ajustamos el modelo, no transformamos los datos\n",
    "\n",
    "    # Obtener nombres originales de las variables\n",
    "    original_feature_names = np.array(X_train.columns)\n",
    "\n",
    "    # Contador de importancia de características en PCA\n",
    "    feature_counter = Counter()\n",
    "    \n",
    "    for comp in pca.components_:\n",
    "        top_indices = np.argsort(np.abs(comp))[-num_top_features:]  # Índices de las más importantes\n",
    "        top_features = original_feature_names[top_indices]  # Obtener nombres\n",
    "        feature_counter.update(top_features)  # Contar ocurrencias\n",
    "\n",
    "    # Seleccionar las variables más influyentes ordenadas por frecuencia de aparición\n",
    "    variables_pca = [feature for feature, _ in feature_counter.most_common()]\n",
    "\n",
    "    # Filtrar las variables seleccionadas en los conjuntos de datos\n",
    "    X_train_filtrado = X_train[variables_pca]\n",
    "    X_val_filtrado = X_val[variables_pca]\n",
    "    \n",
    "    return X_train_filtrado, X_val_filtrado\n",
    "\n",
    "def seleccionar_variables_rfe(X_train, X_val, y_train, num_features):\n",
    "    # Modelo base para RFE\n",
    "    modelo_rf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Aplicar RFE para seleccionar las 20 mejores características\n",
    "    rfe = RFE(estimator=modelo_rf, n_features_to_select=num_features, step=3)\n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "    X_val_rfe = rfe.transform(X_val)\n",
    "\n",
    "    # Ver qué variables fueron seleccionadas\n",
    "    selected_features = X_train.columns[rfe.support_]\n",
    "    \n",
    "    X_train_filtrado = X_train[selected_features]\n",
    "    X_val_filtrado = X_val[selected_features]\n",
    "    \n",
    "    return X_train_filtrado, X_val_filtrado\n",
    "\n",
    "\n",
    "def seleccionar_variables_randomForest(X_train, X_val, y_train, sample_weight_train, num_features):\n",
    "    # Entrenar el modelo RandomForest con los pesos\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train, sample_weight=sample_weight_train)\n",
    "\n",
    "    # Obtener importancia de características\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': rf.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    caracteristicas_imp_rf = feature_importances.head(num_features) \n",
    "    caracteristicas_imp_rf = caracteristicas_imp_rf.Feature.to_list()\n",
    "    # print(caracteristicas_imp_rf)\n",
    "\n",
    "    X_train_processed = X_train[caracteristicas_imp_rf]\n",
    "    X_val_processed = X_val[caracteristicas_imp_rf]\n",
    "    \n",
    "    X_train_processed.shape\n",
    "        \n",
    "    return X_train_processed, X_val_processed\n",
    "\n",
    "\n",
    "def proyectar_tsne(X_train, X_val, n_components, perplexity, max_iter, sample_size, random_state):\n",
    "    \"\"\"\n",
    "    Aplica T-SNE para proyectar los datos a un espacio de menor dimensión.\n",
    "    \n",
    "    Parámetros:\n",
    "        - X_train: DataFrame de entrenamiento\n",
    "        - X_val: DataFrame de validación\n",
    "        - n_components: int, número de dimensiones del embedding\n",
    "        - perplexity: float, parámetro de T-SNE\n",
    "        - n_iter: int, número de iteraciones\n",
    "        - sample_size: int, cantidad de instancias a muestrear para T-SNE\n",
    "        - random_state: int, semilla para reproducibilidad\n",
    "\n",
    "    Retorna:\n",
    "        - X_train_tsne: DataFrame de entrenamiento con la proyección T-SNE\n",
    "        - X_val_tsne: DataFrame de validación con la proyección T-SNE\n",
    "    \"\"\"\n",
    "    # Concatenar datos y muestrear si es necesario\n",
    "    X_all = pd.concat([X_train, X_val])\n",
    "    if X_all.shape[0] > sample_size:\n",
    "        X_all_sample = X_all.sample(n=sample_size, random_state=random_state)\n",
    "    else:\n",
    "        X_all_sample = X_all.copy()\n",
    "\n",
    "    # Aplicar T-SNE\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, max_iter=max_iter, random_state=random_state)\n",
    "    X_all_tsne = tsne.fit_transform(X_all_sample)\n",
    "    df_tsne = pd.DataFrame(X_all_tsne, index=X_all_sample.index, columns=[f'tsne_{i+1}' for i in range(n_components)])\n",
    "    \n",
    "    # Separar proyección en conjuntos de entrenamiento y validación\n",
    "    X_train_tsne = df_tsne.loc[df_tsne.index.intersection(X_train.index)]\n",
    "    X_val_tsne = df_tsne.loc[df_tsne.index.intersection(X_val.index)]\n",
    "    \n",
    "    \n",
    "    return X_train_tsne, X_val_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.960390Z",
     "iopub.status.busy": "2025-03-04T22:00:44.960153Z",
     "iopub.status.idle": "2025-03-04T22:00:44.982406Z",
     "shell.execute_reply": "2025-03-04T22:00:44.981553Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.960371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculo_varianza(df):\n",
    "    \"\"\"Calcula las varianzas de las columnas de un DataFrame y devuelve las que tienen varianza igual a cero.\"\"\"\n",
    "    varianzas = df.var()\n",
    "\n",
    "    # Identificar columnas con varianza igual a cero\n",
    "    variables_con_varianza_cero = [col for col, varianza in varianzas.items() if varianza == 0]\n",
    "    \n",
    "    return variables_con_varianza_cero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:00:44.983733Z",
     "iopub.status.busy": "2025-03-04T22:00:44.983404Z",
     "iopub.status.idle": "2025-03-04T22:01:16.561816Z",
     "shell.execute_reply": "2025-03-04T22:01:16.561075Z",
     "shell.execute_reply.started": "2025-03-04T22:00:44.983704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = replace_common_values(X_train)\n",
    "X_train = fix_mayus(X_train)\n",
    "X_train = fix_dtype(X_train)\n",
    "X_train = delete_ip_port(X_train)\n",
    "\n",
    "y_train_class3 = y_train_class3.loc[X_train.index]\n",
    "y_train_class2 = y_train_class2.loc[X_train.index]\n",
    "y_train_class1 = y_train_class1.loc[X_train.index]\n",
    "\n",
    "X_val = replace_common_values(X_val)\n",
    "X_val = fix_mayus(X_val)\n",
    "X_val = fix_dtype(X_val)\n",
    "X_val = delete_ip_port(X_val)\n",
    "\n",
    "y_val_class3 = y_val_class3.loc[X_val.index]\n",
    "y_val_class2 = y_val_class2.loc[X_val.index]\n",
    "y_val_class1 = y_val_class1.loc[X_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:20:27.080514Z",
     "iopub.status.busy": "2025-03-04T22:20:27.080077Z",
     "iopub.status.idle": "2025-03-04T22:20:31.272883Z",
     "shell.execute_reply": "2025-03-04T22:20:31.271899Z",
     "shell.execute_reply.started": "2025-03-04T22:20:27.080476Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Instancias completas: 416933, incompletas: 157650\n"
     ]
    }
   ],
   "source": [
    "X_train['Instancia_completa'] = X_train.notnull().all(axis=1).astype(int)\n",
    "X_val['Instancia_completa'] = X_val.notnull().all(axis=1).astype(int)\n",
    "\n",
    "completas = X_train['Instancia_completa'].sum()\n",
    "incompletas = len(X_train) - completas\n",
    "print(f\"✅ Instancias completas: {completas}, incompletas: {incompletas}\")\n",
    "sample_weight_train = X_train['Instancia_completa'].replace({1: 3, 0: 1})\n",
    "\n",
    "columnas_no_comprobar = [col for col in X_train.columns if col not in ['Timestamp', 'Date', 'Instancia_completa'] and X_train[col].dtypes != 'object']\n",
    "variables_con_varianza_cero = calculo_varianza(X_train[columnas_no_comprobar])\n",
    "X_train = X_train.drop(columns=variables_con_varianza_cero)\n",
    "X_val = X_val.drop(columns=variables_con_varianza_cero)\n",
    "    \n",
    "X_train = X_train.drop(columns=['Timestamp', 'Date', 'Instancia_completa'], errors='ignore')\n",
    "X_val = X_val.drop(columns=['Timestamp', 'Date', 'Instancia_completa'], errors='ignore')\n",
    "\n",
    "alta_corr_pares = correlacion_pares(X_train, 0.97)\n",
    "X_train = X_train.drop(columns=alta_corr_pares)\n",
    "X_val = X_val.drop(columns=alta_corr_pares)\n",
    "\n",
    "baja_corr_respecto_obj = correlacion_respecto_objetivo(X_train, y_train_class3, 0.025)\n",
    "X_train = X_train.drop(columns=baja_corr_respecto_obj)\n",
    "X_val = X_val.drop(columns=baja_corr_respecto_obj)\n",
    "\n",
    "caracteritisticas_seleccionadas = X_train.columns.tolist()\n",
    "\n",
    "X_train['Protocol'] = X_train['Protocol'].fillna(\"missing\")\n",
    "X_val['Protocol'] = X_val['Protocol'].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:21.406854Z",
     "iopub.status.busy": "2025-03-04T22:01:21.406638Z",
     "iopub.status.idle": "2025-03-04T22:01:24.205399Z",
     "shell.execute_reply": "2025-03-04T22:01:24.204668Z",
     "shell.execute_reply.started": "2025-03-04T22:01:21.406835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " # Identificar columnas categóricas, numéricas y booleanas\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "boolean_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "if boolean_cols.any():  # Si hay columnas booleanas\n",
    "    X_train[boolean_cols] = X_train[boolean_cols].astype(float)  # TAL VEZ INNCESESARIO\n",
    "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "##############################################################################\n",
    "    \n",
    "X_train[categorical_cols] = imputador_cat.fit_transform(X_train[categorical_cols])\n",
    "X_val[categorical_cols] = imputador_cat.transform(X_val[categorical_cols])\n",
    "\n",
    "X_train[numerical_cols] = imputador_num.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = imputador_num.transform(X_val[numerical_cols])\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_train_scaled = normalizacion.fit_transform(X_train[numerical_cols])\n",
    "X_val_scaled = normalizacion.transform(X_val[numerical_cols])\n",
    "\n",
    "# Convertir las matrices escaladas a DataFrames\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=[f\"{col}_scaled\" for col in numerical_cols], index=X_train.index)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=[f\"{col}_scaled\" for col in numerical_cols], index=X_val.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_train_encoded = decodificador.fit_transform(X_train[categorical_cols])\n",
    "X_val_encoded = decodificador.transform(X_val[categorical_cols])\n",
    "\n",
    "# Obtener los nombres de las nuevas columnas codificadas\n",
    "encoded_cols = decodificador.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Convertir las matrices codificadas a DataFrames\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_cols, index=X_train.index)\n",
    "X_val_encoded_df = pd.DataFrame(X_val_encoded, columns=encoded_cols, index=X_val.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Combinar con las características categóricas codificadas\n",
    "X_train_processed = pd.concat([X_train_scaled_df, X_train_encoded_df], axis=1)\n",
    "X_val_processed = pd.concat([X_val_scaled_df, X_val_encoded_df], axis=1)\n",
    "\n",
    "# Opcional: Reordenar las columnas si es necesario\n",
    "X_train = X_train_processed.reindex(sorted(X_train_processed.columns), axis=1)\n",
    "X_val = X_val_processed.reindex(sorted(X_val_processed.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:24.206527Z",
     "iopub.status.busy": "2025-03-04T22:01:24.206304Z",
     "iopub.status.idle": "2025-03-04T22:01:25.341273Z",
     "shell.execute_reply": "2025-03-04T22:01:25.340581Z",
     "shell.execute_reply.started": "2025-03-04T22:01:24.206506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val = seleccionar_variables_pca(X_train_processed, X_val_processed, n_components=0.95, num_top_features=20)\n",
    "caracteritisticas_procesadas = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:25.342409Z",
     "iopub.status.busy": "2025-03-04T22:01:25.342152Z",
     "iopub.status.idle": "2025-03-04T22:01:25.422582Z",
     "shell.execute_reply": "2025-03-04T22:01:25.421765Z",
     "shell.execute_reply.started": "2025-03-04T22:01:25.342387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574583, 34) (123125, 34)\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape)\n",
    "print(X_train.isnull().sum().sum(), X_val.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_class1 = LabelEncoder()\n",
    "y_train_class1 = label_encoder_class1.fit_transform(y_train_class1)\n",
    "y_val_class1   = label_encoder_class1.transform(y_val_class1)\n",
    "y_test_class1  = label_encoder_class1.transform(y_test_class1)\n",
    "\n",
    "mapping_class1 = dict(enumerate(label_encoder_class1.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'BruteForce', 1: 'C&C', 2: 'Dictionary', 3: 'Discovering_resources', 4: 'Exfiltration', 5: 'Fake_notification', 6: 'False_data_injection', 7: 'Generic_scanning', 8: 'MQTT_cloud_broker_subscription', 9: 'MitM', 10: 'Modbus_register_reading', 11: 'Normal', 12: 'RDOS', 13: 'Reverse_shell', 14: 'Scanning_vulnerability', 15: 'TCP Relay', 16: 'crypto-ransomware', 17: 'fuzzing', 18: 'insider_malcious'}\n"
     ]
    }
   ],
   "source": [
    "print(mapping_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:01:25.423503Z",
     "iopub.status.busy": "2025-03-04T22:01:25.423293Z",
     "iopub.status.idle": "2025-03-04T22:01:25.501060Z",
     "shell.execute_reply": "2025-03-04T22:01:25.500214Z",
     "shell.execute_reply.started": "2025-03-04T22:01:25.423484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  # Número de características de entrada\n",
    "num_classes_1 = len(set(y_train_class1))  # Cantidad de clases en y_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:33.921425Z",
     "iopub.status.busy": "2025-03-04T22:02:33.921089Z",
     "iopub.status.idle": "2025-03-04T22:02:33.950982Z",
     "shell.execute_reply": "2025-03-04T22:02:33.950095Z",
     "shell.execute_reply.started": "2025-03-04T22:02:33.921401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train_class1 = y_train_class1.ravel()\n",
    "y_val_class1 = y_val_class1.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:02:34.061773Z",
     "iopub.status.busy": "2025-03-04T22:02:34.061491Z",
     "iopub.status.idle": "2025-03-04T22:02:51.356674Z",
     "shell.execute_reply": "2025-03-04T22:02:51.355961Z",
     "shell.execute_reply.started": "2025-03-04T22:02:34.061751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.2364 - val_accuracy: 0.9831 - val_loss: 0.0550\n",
      "Epoch 2/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0559 - val_accuracy: 0.9848 - val_loss: 0.0479\n",
      "Epoch 3/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.0460 - val_accuracy: 0.9827 - val_loss: 0.0505\n",
      "Epoch 4/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0428 - val_accuracy: 0.9863 - val_loss: 0.0441\n",
      "Epoch 5/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0395 - val_accuracy: 0.9872 - val_loss: 0.0389\n",
      "Epoch 6/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0375 - val_accuracy: 0.9873 - val_loss: 0.0379\n",
      "Epoch 7/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.0346 - val_accuracy: 0.9871 - val_loss: 0.0435\n",
      "Epoch 8/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0334 - val_accuracy: 0.9879 - val_loss: 0.0384\n",
      "Epoch 9/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0325 - val_accuracy: 0.9889 - val_loss: 0.0346\n",
      "Epoch 10/10\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0322 - val_accuracy: 0.9897 - val_loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: modelos_dnn_opcion2\\dnn_class1.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Entrada\n",
    "input_layer = keras.Input(shape=(input_dim,))\n",
    "\n",
    "# Capas ocultas\n",
    "x = layers.Dense(200, activation='relu')(input_layer)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "\n",
    "# Salida\n",
    "output_class1 = layers.Dense(num_classes_1, activation='softmax', name=\"output_class1\")(x)  # Multiclase\n",
    "\n",
    "# Modelo con dos salidas\n",
    "model = keras.Model(inputs=input_layer, outputs=[output_class1])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=['sparse_categorical_crossentropy'],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train,\n",
    "                    y_train_class1,\n",
    "                    batch_size=250,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_val, y_val_class1))\n",
    "\n",
    "\n",
    "# Guardar el modelo con un nombre único\n",
    "model_name = f\"dnn_class1\"\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "carpeta_modelos = \"modelos_dnn_opcion2\"\n",
    "os.makedirs(carpeta_modelos, exist_ok=True)\n",
    "\n",
    "# Guardar el modelo dentro de la carpeta\n",
    "ruta_modelo = os.path.join(carpeta_modelos, f\"{model_name}.h5\")\n",
    "model.save(ruta_modelo)\n",
    "\n",
    "print(f\"Modelo guardado en: {ruta_modelo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:23:04.513589Z",
     "iopub.status.busy": "2025-03-04T22:23:04.513289Z",
     "iopub.status.idle": "2025-03-04T22:23:09.940421Z",
     "shell.execute_reply": "2025-03-04T22:23:09.939141Z",
     "shell.execute_reply.started": "2025-03-04T22:23:04.513567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = replace_common_values(X_test)\n",
    "X_test = fix_mayus(X_test)\n",
    "X_test = fix_dtype(X_test)\n",
    "X_test = delete_ip_port(X_test)\n",
    "\n",
    "y_test_class3 = y_test_class3[X_test.index]\n",
    "\n",
    "X_test = X_test[caracteritisticas_seleccionadas] \n",
    "\n",
    "X_test['Protocol'] = X_test['Protocol'].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T22:22:19.991724Z",
     "iopub.status.busy": "2025-03-04T22:22:19.991425Z",
     "iopub.status.idle": "2025-03-04T22:22:20.078513Z",
     "shell.execute_reply": "2025-03-04T22:22:20.077337Z",
     "shell.execute_reply.started": "2025-03-04T22:22:19.991701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Identificar columnas categóricas, numéricas y booleanas\n",
    "categorical_cols = X_test.select_dtypes(include=['object']).columns\n",
    "boolean_cols = X_test.select_dtypes(include=['bool']).columns\n",
    "if boolean_cols.any():  # Si hay columnas booleanas\n",
    "    X_test[boolean_cols] = X_test[boolean_cols].astype(float) # TAL VEZ INNCESESARIO\n",
    "numerical_cols = X_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_test[categorical_cols] = imputador_cat.transform(X_test[categorical_cols])\n",
    "\n",
    "X_test[numerical_cols] = imputador_num.transform(X_test[numerical_cols])\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_test_scaled = normalizacion.transform(X_test[numerical_cols])\n",
    "\n",
    "# Convertir las matrices escaladas a DataFrames\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=[f\"{col}_scaled\" for col in numerical_cols], index=X_test.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "X_test_encoded = decodificador.transform(X_test[categorical_cols])\n",
    "\n",
    "# Obtener los nombres de las nuevas columnas codificadas\n",
    "encoded_cols = decodificador.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Convertir las matrices codificadas a DataFrames\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_cols, index=X_test.index)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Combinar con las características categóricas codificadas\n",
    "X_test_processed = pd.concat([X_test_scaled_df, X_test_encoded_df], axis=1)\n",
    "\n",
    "# Opcional: Reordenar las columnas si es necesario\n",
    "X_test_processed = X_test_processed.reindex(sorted(X_test_processed.columns), axis=1)\n",
    "\n",
    "X_test = X_test_processed[caracteritisticas_procesadas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clase1 Mapping: {0: 'BruteForce', 1: 'C&C', 2: 'Dictionary', 3: 'Discovering_resources', 4: 'Exfiltration', 5: 'Fake_notification', 6: 'False_data_injection', 7: 'Generic_scanning', 8: 'MQTT_cloud_broker_subscription', 9: 'MitM', 10: 'Modbus_register_reading', 11: 'RDOS', 12: 'Reverse_shell', 13: 'Scanning_vulnerability', 14: 'TCP Relay', 15: 'crypto-ransomware', 16: 'fuzzing', 17: 'insider_malcious'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3848/3848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "📈 Accuracy (Test): 0.9894\n",
      "📈 Precision (Test): 0.9589\n",
      "📈 Recall (Test): 0.9167\n",
      "📈 F1 (Test): 0.9347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "y_test_class1 = y_test_class1.ravel()\n",
    "\n",
    "# Predicción para salida de clase3\n",
    "y_pred_class1 = model.predict(X_test)\n",
    "y_pred_class1 = np.argmax(y_pred_class1, axis=1) \n",
    "y_pred_class1_names = label_encoder_class1.inverse_transform(y_pred_class1)\n",
    "\n",
    "predicciones_df = pd.DataFrame({'Predicciones_Class1': y_pred_class1_names.ravel()})  \n",
    "ruta_directorio = '../../predicciones'\n",
    "os.makedirs(ruta_directorio, exist_ok=True)\n",
    "predicciones_df.to_csv(os.path.join(ruta_directorio, 'arq2.csv'), index=False)\n",
    "\n",
    "accuracy = accuracy_score(y_test_class1, y_pred_class1)\n",
    "print(f\"📈 Accuracy (Test): {accuracy:.4f}\")\n",
    "precision = precision_score(y_test_class1, y_pred_class1, average='macro')\n",
    "print(f\"📈 Precision (Test): {precision:.4f}\")\n",
    "recall = recall_score(y_test_class1, y_pred_class1, average='macro')\n",
    "print(f\"📈 Recall (Test): {recall:.4f}\")\n",
    "f1 = f1_score(y_test_class1, y_pred_class1, average='macro')\n",
    "print(f\"📈 F1 (Test): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                BruteForce  C&C  Dictionary  Discovering_resources  ...  TCP Relay  crypto-ransomware  fuzzing  insider_malcious\n",
    "BruteForce                            7152    0           0                      0  ...          0                  0        0                 0\n",
    "C&C                                      0  372           0                      1  ...          0                  0        0                 0\n",
    "Dictionary                               0    0         375                      0  ...          0                  0        0                 0\n",
    "Discovering_resources                    0    2           0                   2897  ...          0                  0        0                 0\n",
    "Exfiltration                             0    1           1                      0  ...          0                  0        0                 0\n",
    "Fake_notification                        0    0           0                      0  ...          0                  0        0                 0\n",
    "False_data_injection                     0    0           0                      0  ...          0                  0        0                 0\n",
    "Generic_scanning                         0    0           0                      0  ...          1                  0        0                 0\n",
    "MQTT_cloud_broker_subscription           0    0           0                      0  ...          1                  0        0                 0\n",
    "MitM                                     0    0           0                      0  ...          0                  0        0                 0\n",
    "Modbus_register_reading                  0    0           0                      0  ...          0                  0        0                 0\n",
    "Normal                                   0   60           0                    236  ...         46                  1       12                 3\n",
    "RDOS                                     0    0           0                      4  ...          0                  0        0                 0\n",
    "Reverse_shell                            0    0           0                      0  ...          9                  0        0                 0\n",
    "Scanning_vulnerability                   0    0           5                      0  ...          2                  0        0                 0\n",
    "TCP Relay                                0    0           0                      0  ...        234                  0        0                 0\n",
    "crypto-ransomware                        0    0           0                      0  ...          0                 72        0                 0\n",
    "fuzzing                                  0    0           0                      0  ...          0                  0      137                 0\n",
    "insider_malcious                         0    0           0                      0  ...          0                  0        0              2638\n",
    "\n",
    "[19 rows x 19 columns]\n",
    "                                precision    recall  f1-score   support\n",
    "\n",
    "                    BruteForce     1.0000    1.0000    1.0000      7152\n",
    "                           C&C     0.8552    0.8513    0.8532       437\n",
    "                    Dictionary     0.9843    0.9973    0.9908       376\n",
    "         Discovering_resources     0.9232    0.8404    0.8799      3447\n",
    "                  Exfiltration     0.9997    0.9988    0.9992      3291\n",
    "             Fake_notification     1.0000    0.6667    0.8000         3\n",
    "          False_data_injection     0.9540    0.9947    0.9739       751\n",
    "              Generic_scanning     0.9966    0.9978    0.9972      7559\n",
    "MQTT_cloud_broker_subscription     0.9958    0.9938    0.9948      3546\n",
    "                          MitM     0.9333    0.8750    0.9032        16\n",
    "       Modbus_register_reading     0.9979    0.9968    0.9973       933\n",
    "                        Normal     0.9875    0.9933    0.9904     63213\n",
    "                          RDOS     0.9997    0.9993    0.9995     21095\n",
    "                 Reverse_shell     0.8905    0.8356    0.8622       146\n",
    "        Scanning_vulnerability     0.9980    0.9984    0.9982      7921\n",
    "                     TCP Relay     0.7986    0.7178    0.7561       326\n",
    "             crypto-ransomware     0.9863    0.9863    0.9863        73\n",
    "                       fuzzing     0.9195    0.6749    0.7784       203\n",
    "              insider_malcious     0.9989    1.0000    0.9994      2638\n",
    "\n",
    "                      accuracy                         0.9894    123126\n",
    "                     macro avg     0.9589    0.9167    0.9347    123126\n",
    "                  weighted avg     0.9892    0.9894    0.9892    123126\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                   C&C  Exfiltration  Exploitation  Lateral _movement  Normal   RDOS  Reconnaissance  Tampering  Weaponization  crypto-ransomware\n",
    "C&C                372             0             0                  0      64      0               1          0              0                  0\n",
    "Exfiltration         1          3287             0                  0       0      0               2          0              1                  0\n",
    "Exploitation         0             0           136                 12       4      0              10          0              0                  0\n",
    "Lateral _movement    0             0             8               4689      90      0               8         10              0                  0\n",
    "Normal              60             0             8                 51   62791      7             266         26              3                  1\n",
    "RDOS                 0             0             0                  0      10  21081               4          0              0                  0\n",
    "Reconnaissance       2             1             0                  8     627      0           18487          0              5                  0\n",
    "Tampering            0             0             0                  4       1      0               0        749              0                  0\n",
    "Weaponization        0             0             0                  0       0      0               1          0          10165                  0\n",
    "crypto-ransomware    0             0             0                  0       1      0               0          0              0                 72\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "              C&C     0.8552    0.8513    0.8532       437\n",
    "     Exfiltration     0.9997    0.9988    0.9992      3291\n",
    "     Exploitation     0.8947    0.8395    0.8662       162\n",
    "Lateral _movement     0.9843    0.9759    0.9800      4805\n",
    "           Normal     0.9875    0.9933    0.9904     63213\n",
    "             RDOS     0.9997    0.9993    0.9995     21095\n",
    "   Reconnaissance     0.9845    0.9664    0.9753     19130\n",
    "        Tampering     0.9541    0.9934    0.9734       754\n",
    "    Weaponization     0.9991    0.9999    0.9995     10166\n",
    "crypto-ransomware     0.9863    0.9863    0.9863        73\n",
    "\n",
    "         accuracy                         0.9895    123126\n",
    "        macro avg     0.9645    0.9604    0.9623    123126\n",
    "     weighted avg     0.9895    0.9895    0.9894    123126"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6649121,
     "sourceId": 10725550,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
